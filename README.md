## Introduction
æœ¬ç‰ˆæœ¬åœ¨ https://github.com/microsoft/graphrag çš„ Commit:61b5eea åŸºç¡€ä¸Šï¼Œå¢åŠ äº†å¯¹qwenå¤§æ¨¡å‹çš„æ”¯æŒã€‚

## Why do this
ä½œä¸ºä¸€ä¸ªæ‰å¼€æºä¸ä¹…çš„äº§å“ï¼Œ`GraphRAG`å°šä¸å®Œå–„ï¼Œä¾‹å¦‚ï¼š

* `GraphRAG`æ˜¯åŸºäº`OpenAI`å¼€å‘çš„ï¼Œæ•°æ®æ ¼å¼éƒ½é‡‡ç”¨`OpenAI`æ ‡å‡†ï¼Œä½†å…¶ä»–å¤§æ¨¡å‹å¹¶ä¸ä¸€å®šè¿™æ ·ã€‚ä¸¾ä¾‹ï¼šåœ¨è¿”å›`embedding`æ•°æ®æ—¶ï¼Œ`OpenAI`çš„è¿”å›å€¼ä¸`ollama`ï¼Œä»¥åŠ`çµç§¯dashscope`è¿”å›çš„å€¼ä¸åŒã€‚

* åœ¨`OpenAI`ä¸Šè·‘`GraphRAG`æ—¶ï¼Œè´¹ç”¨å¾ˆé«˜ï¼Œè€Œä¸”æœ‰äº›å›½å®¶æ— æ³•ä½¿ç”¨`OpenAI`çš„APIï¼Œå¦‚æœè¦åœ¨`llama3`ç­‰å¼€æºæ¨¡å‹ï¼Œæˆ–ç”¨`ollama`ç­‰æœ¬åœ°å¤§æ¨¡å‹ä¸Šè¿è¡Œçš„è¯ï¼Œéœ€è¦å¢åŠ å¤§é‡è¾…åŠ©å·¥ä½œã€‚å¦‚æœèƒ½åœ¨`GraphRAG`ä¸­ï¼Œé€šè¿‡ç®€å•çš„é…ç½®ï¼Œå°±é€‚é…å¤§å¤šæ•°å¤§æ¨¡å‹ï¼Œè®©æ›´å¤šçš„äººæ–¹ä¾¿åœ°ä½“éªŒ`GraphRAG`ã€‚

* æœ‰äº›æŠ€æœ¯çˆ±å¥½è€…æƒ³åœ¨ä½é…ç½®ç¬”è®°æœ¬ä¸Šè¿è¡Œ`GraphRAG`ï¼Œä½†æ²¡æœ‰`OpenAI`çš„APIï¼Œè€Œä½¿ç”¨éOpenAIå¤§æ¨¡å‹æ—¶ï¼ŒåŸç”Ÿ`GraphRAG`æ— æ³•ç›´æ¥æ”¯æŒã€‚

* ä¸€äº›å›½äº§çš„å¤§æ¨¡å‹å¯¹ä¸­æ–‡çš„æ”¯æŒè¾ƒå¥½ï¼Œåœ¨å¼€å‘ä¸­æ–‡GPTåº”ç”¨æ—¶ï¼Œå›½äº§å¤§æ¨¡å‹æ›´å‡†ç¡®ï¼Œå¦‚æœèƒ½é…åˆ`GraphRAG`çŸ¥è¯†å›¾è°±ï¼Œå°†å¤§å¹…åŠ é€Ÿäººå·¥æ™ºèƒ½åœ¨å®é™…å•†ä¸šé¢†åŸŸçš„åº”ç”¨ã€‚

## Quickstart
å¦‚æœéœ€è¦ä½¿ç”¨`qwenå¤§æ¨¡å‹`åŠ ä¸qwené…å¥—çš„å¤šè¯­è¨€æ–‡æœ¬å‘é‡æ¨¡å‹çš„è¯ï¼Œåªè¦æŒ‰ä¸‹é¢æ­£ç¡®è®¾ç½®`settings.yaml`å³å¯ï¼Œå®‰è£…ä¸è¿è¡ŒåŒå®˜æ–¹æ–‡æ¡£ã€‚

åŒºåˆ«ä»…åœ¨äºå…‹éš†æœ¬repoä»£ç ï¼Œå³ï¼š
```
git clone https://github.com/jackygu2006/graphrag.git
```
å…¶ä»–å‚ç…§å®˜æ–¹æ–‡æ¡£ï¼Œè™½ç„¶ä½¿ç”¨pipä¹Ÿå¯ä»¥å®‰è£…ï¼Œä½†æˆ‘åå¥½ç”¨poetryï¼ˆä½œä¸ºä¸€ånodejså¼€å‘è€…ï¼Œpythonä¸Šçš„åº“ç®¡ç†å·¥å…·poetryå’Œyarnå¤ªåƒäº†ğŸ˜ï¼‰


ä¸‹é¢æ˜¯`settings.yaml`çš„æ¨èé…ç½®ï¼š
éœ€è¦æ³¨æ„ï¼š
* `llm/model`ï¼šå¦‚æœéœ€è¦æ¢æˆå…¶ä»–qwençš„å¤§æ¨¡å‹ï¼Œåœ¨è¿™é‡Œè°ƒæ•´ï¼Œå¦‚ï¼š`qwen-turbo`, `qwen-long`ç­‰
* `llm/api_base`ï¼šå¦‚æœä½¿ç”¨qwenå¤§æ¨¡å‹ï¼Œå¿…é¡»å†™ï¼šhttps://dashscope.aliyuncs.com/compatible-mode/v1
* `llm/max_tokens`ï¼šå› ä¸ºqwenå¤§æ¨¡å‹çš„é™åˆ¶ï¼Œå¿…é¡»æ˜¯2000ï¼Œå…¶ä»–å‚æ•°ä¹Ÿç”¨ä¸‹é¢çš„å³å¯ï¼Œæ³¨æ„`top_p`å¿…é¡»åœ¨0åˆ°1ä¹‹é—´ï¼Œä¸èƒ½æ˜¯0å’Œ1
* `embeddings/llm/type`: å¿…é¡»å†™`qwen_embedding`ï¼Œè¿™æ˜¯æˆ‘æ–°å¢çš„ç±»åˆ«
* `embeddings/llm/model`: æˆ‘è¿™é‡Œä½¿ç”¨`text-embedding-v2`æ–‡æœ¬å‘é‡ï¼Œå…·ä½“å‚è§[è¿™é‡Œ](https://help.aliyun.com/zh/dashscope/developer-reference/text-embedding-quick-start?spm=a2c4g.11186623.0.0.397e2fb4RD75YF)
* `embeddings/llm/max_tokens`: å¡«2048ï¼Œå› ä¸ºè¯¥å‘é‡æ¨¡å‹çš„é™åˆ¶ã€‚å…¶ä»–æŒ‰ä¸‹é¢é…ç½®å³å¯ã€‚
* `global_search`ï¼šæŒ‰ä¸‹é¢é…ç½®ï¼Œå®˜æ–¹æ–‡æ¡£ä¸­æ²¡æœ‰`llm_top_p`ï¼Œä½†å› ä¸ºqwenä¸æ”¯æŒtop_p=1ï¼Œæ‰€ä»¥éœ€è¦æ‰“å¼€è¿™ä¸ªé€‰é¡¹ï¼Œå¹¶è®¾ç½®ä¸€ä¸ªæ¯”1å°çš„å€¼ï¼Œå¦åˆ™æ— æ³•æ‰§è¡Œæ¨ç†ã€‚
* `local_search`: åŒ`global_search`ã€‚

```
encoding_model: cl100k_base
skip_workflows: []
llm:
  api_key: ${GRAPHRAG_API_KEY}
  type: openai_chat
  model: qwen-max
  model_supports_json: true # recommended if this is available for your model.
  api_base: https://dashscope.aliyuncs.com/compatible-mode/v1
  max_tokens: 2000
  tokens_per_minute: 30000
  requests_per_minute: 30
  max_retries: 3
  max_retry_wait: 10
  sleep_on_rate_limit_recommendation: true
	suggests wait-times
  concurrent_requests: 1
  top_p: 0.85 # limit for qwen

parallelization:
  stagger: 0.3
  # num_threads: 50 # the number of threads to use for parallel processing

async_mode: threaded # or asyncio

embeddings:
  async_mode: threaded # or asyncio
  llm:
    api_key: ${GRAPHRAG_API_KEY}
    type: qwen_embedding
    model: text-embedding-v2
    api_base: https://dashscope.aliyuncs.com/compatible-mode/v1
    max_tokens: 2048
    tokens_per_minute: 30000 # set a leaky bucket throttle
    requests_per_minute: 30 # set a leaky bucket throttle
    max_retries: 3
    max_retry_wait: 10.0
    sleep_on_rate_limit_recommendation: true # whether to sleep when azure suggests wait-times
    concurrent_requests: 1 # the number of parallel inflight requests that may be made  
    top_p: 0.85

chunks:
  size: 300
  overlap: 100
  group_by_columns: [id] # by default, we don't allow chunks to cross documents
    
input:
  type: file # or blob
  file_type: text # or csv
  base_dir: "input"
  file_encoding: utf-8
  file_pattern: ".*\\.txt$"

cache:
  type: file # or blob
  base_dir: "cache"
  # connection_string: <azure_blob_storage_connection_string>
  # container_name: <azure_blob_storage_container_name>

storage:
  type: file # or blob
  base_dir: "output/${timestamp}/artifacts"
  # connection_string: <azure_blob_storage_connection_string>
  # container_name: <azure_blob_storage_container_name>

reporting:
  type: file # or console, blob
  base_dir: "output/${timestamp}/reports"
  # connection_string: <azure_blob_storage_connection_string>
  # container_name: <azure_blob_storage_container_name>

entity_extraction:
  ## llm: override the global llm settings for this task
  ## parallelization: override the global parallelization settings for this task
  ## async_mode: override the global async_mode settings for this task
  prompt: "prompts/entity_extraction.txt"
  entity_types: [organization,person,geo,event]
  max_gleanings: 0

summarize_descriptions:
  ## llm: override the global llm settings for this task
  ## parallelization: override the global parallelization settings for this task
  ## async_mode: override the global async_mode settings for this task
  prompt: "prompts/summarize_descriptions.txt"
  max_length: 500

claim_extraction:
  ## llm: override the global llm settings for this task
  ## parallelization: override the global parallelization settings for this task
  ## async_mode: override the global async_mode settings for this task
  # enabled: true
  prompt: "prompts/claim_extraction.txt"
  description: "Any claims or facts that could be relevant to information discovery."
  max_gleanings: 0

community_report:
  ## llm: override the global llm settings for this task
  ## parallelization: override the global parallelization settings for this task
  ## async_mode: override the global async_mode settings for this task
  prompt: "prompts/community_report.txt"
  max_length: 2000
  max_input_length: 8000

cluster_graph:
  max_cluster_size: 10

embed_graph:
  enabled: false # if true, will generate node2vec embeddings for nodes
  # num_walks: 10
  # walk_length: 40
  # window_size: 2
  # iterations: 3
  # random_seed: 597832

umap:
  enabled: false # if true, will generate UMAP embeddings for nodes

snapshots:
  graphml: false
  raw_entities: false
  top_level_nodes: false

local_search:
  text_unit_prop: 0.6
  community_prop: 0.1
  conversation_history_max_turns: 5
  top_k_mapped_entities: 10
  top_k_relationships: 10
  max_tokens: 2000
  llm_top_p: 0.85

global_search:
  max_tokens: 2000
  data_max_tokens: 2000
  map_max_tokens: 2000
  reduce_max_tokens: 2000
  concurrency: 1
  llm_top_p: 0.85

```

## TODO
å¤§è¯­è¨€æ¨¡å‹å‘å±•å¾ˆå¿«ï¼Œç‰ˆæœ¬çš„è¿­ä»£æ›´å¿«ï¼Œæˆ‘å¸Œæœ›èƒ½å°½å¯èƒ½å¤šçš„æŠŠGraphRAGåœ¨ä¸åŒçš„å¤§æ¨¡å‹ä¸Šè¿è¡Œã€‚

* <input type="checkbox" name="option" value="option1" checked>  æ”¯æŒçµç§¯å¹³å°ä¸Šçš„æ–‡æœ¬å‘é‡embeddingæ¨¡å‹
* <input type="checkbox" name="option" value="option1">  æ”¯æŒçµç§¯å¹³å°ä¸Šéqwenç³»åˆ—å¤§æ¨¡å‹çš„æ”¯æŒï¼Œå¦‚ï¼šllama3ï¼Œç™¾å·å¤§æ¨¡å‹ï¼ŒGLMå¤§æ¨¡å‹ç­‰ç­‰ã€‚
* <input type="checkbox" name="option" value="option1">  æ”¯æŒè±†åŒ…å¹³å°ä¸Šçš„å¤§æ¨¡å‹ä»¥åŠè±†åŒ…çš„æ–‡æœ¬å‘é‡
* <input type="checkbox" name="option" value="option1">  æ”¯æŒollamaæœ¬åœ°å¤§æ¨¡å‹


## ä»¥ä¸‹æ˜¯GraphRAGå®˜æ–¹æ–‡æ¡£ ğŸ‘‡ğŸ‘‡ğŸ‘‡
# GraphRAG

ğŸ‘‰ [Use the GraphRAG Accelerator solution](https://github.com/Azure-Samples/graphrag-accelerator) <br/>
ğŸ‘‰ [Microsoft Research Blog Post](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)<br/>
ğŸ‘‰ [Read the docs](https://microsoft.github.io/graphrag)<br/>
ğŸ‘‰ [GraphRAG Arxiv](https://arxiv.org/pdf/2404.16130)

<div align="left">
  <a href="https://pypi.org/project/graphrag/">
    <img alt="PyPI - Version" src="https://img.shields.io/pypi/v/graphrag">
  </a>
  <a href="https://pypi.org/project/graphrag/">
    <img alt="PyPI - Downloads" src="https://img.shields.io/pypi/dm/graphrag">
  </a>
  <a href="https://github.com/microsoft/graphrag/issues">
    <img alt="GitHub Issues" src="https://img.shields.io/github/issues/microsoft/graphrag">
  </a>
  <a href="https://github.com/microsoft/graphrag/discussions">
    <img alt="GitHub Discussions" src="https://img.shields.io/github/discussions/microsoft/graphrag">
  </a>
</div>

## Overview

The GraphRAG project is a data pipeline and transformation suite that is designed to extract meaningful, structured data from unstructured text using the power of LLMs.

To learn more about GraphRAG and how it can be used to enhance your LLMs ability to reason about your private data, please visit the <a href="https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/" target="_blank">Microsoft Research Blog Post.</a>

## Quickstart

To get started with the GraphRAG system we recommend trying the [Solution Accelerator](https://github.com/Azure-Samples/graphrag-accelerator) package. This provides a user-friendly end-to-end experience with Azure resources.

## Repository Guidance

This repository presents a methodology for using knowledge graph memory structures to enhance LLM outputs. Please note that the provided code serves as a demonstration and is not an officially supported Microsoft offering.

âš ï¸ *Warning: GraphRAG indexing can be an expensive operation, please read all of the documentation to understand the process and costs involved, and start small.*

## Diving Deeper

- To learn about our contribution guidelines, see [CONTRIBUTING.md](./CONTRIBUTING.md)
- To start developing _GraphRAG_, see [DEVELOPING.md](./DEVELOPING.md)
- Join the conversation and provide feedback in the [GitHub Discussions tab!](https://github.com/microsoft/graphrag/discussions)

## Prompt Tuning

Using _GraphRAG_ with your data out of the box may not yield the best possible results.
We strongly recommend to fine-tune your prompts following the [Prompt Tuning Guide](https://microsoft.github.io/graphrag/posts/prompt_tuning/overview/) in our documentation.

## Responsible AI FAQ

See [RAI_TRANSPARENCY.md](./RAI_TRANSPARENCY.md)

- [What is GraphRAG?](./RAI_TRANSPARENCY.md#what-is-graphrag)
- [What can GraphRAG do?](./RAI_TRANSPARENCY.md#what-can-graphrag-do)
- [What are GraphRAGâ€™s intended use(s)?](./RAI_TRANSPARENCY.md#what-are-graphrags-intended-uses)
- [How was GraphRAG evaluated? What metrics are used to measure performance?](./RAI_TRANSPARENCY.md#how-was-graphrag-evaluated-what-metrics-are-used-to-measure-performance)
- [What are the limitations of GraphRAG? How can users minimize the impact of GraphRAGâ€™s limitations when using the system?](./RAI_TRANSPARENCY.md#what-are-the-limitations-of-graphrag-how-can-users-minimize-the-impact-of-graphrags-limitations-when-using-the-system)
- [What operational factors and settings allow for effective and responsible use of GraphRAG?](./RAI_TRANSPARENCY.md#what-operational-factors-and-settings-allow-for-effective-and-responsible-use-of-graphrag)

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.

## Privacy

[Microsoft Privacy Statement](https://privacy.microsoft.com/en-us/privacystatement)
